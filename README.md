# llm-perf

Build a simulation or profiler-based model predicting inference latency for different batching, sequence lengths, and GPU configs.

Add NVTX markers to custom attention kernels, visualize overlapping compute/memory ops using Nsight Systems.
